{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import pandas\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_folder = 'data/train'\n",
    "test_folder = 'data/test'\n",
    "validation_folder = 'data/validation'\n",
    "labels_csv = 'train_labels.csv'\n",
    "label_names = ['0', '1']\n",
    "IMG_WIDTH = 450\n",
    "IMG_HEIGHT = 450\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders are already labelled\n"
     ]
    }
   ],
   "source": [
    "utils.create_labelled_folders(train_folder, labels_csv, label_names)        \n",
    "utils.create_validation_subfolders(train_folder, validation_folder, label_names, 0.2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1837 images belonging to 2 classes.\n",
      "Found 458 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rescale=1./255.,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=90\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    batch_size=batch_size,\n",
    "    target_size = (IMG_WIDTH, IMG_HEIGHT)\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_folder,\n",
    "    batch_size=batch_size,\n",
    "    target_size = (IMG_WIDTH, IMG_HEIGHT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.vgg16.VGG16(weights='imagenet', \n",
    "                                            include_top=False, \n",
    "                                            input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), \n",
    "                                            classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = (Flatten(input_shape=base_model.output_shape[1:], name=\"finetune\"))(x)\n",
    "x = (Dense(256, activation='relu'))(x)\n",
    "x = (Dropout(0.5))(x)\n",
    "x = (Dense(2, activation='sigmoid'))(x)\n",
    "\n",
    "model = Model(inputs=base_model.inputs, outputs=x)\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name == \"block5_conv3\":\n",
    "        break\n",
    "    \n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "229/229 [==============================] - 334s - loss: 0.1811 - acc: 0.9350 - val_loss: 0.1456 - val_acc: 0.9496\n",
      "Epoch 2/50\n",
      "229/229 [==============================] - 215s - loss: 0.1670 - acc: 0.9293 - val_loss: 0.1525 - val_acc: 0.9500\n",
      "Epoch 3/50\n",
      "229/229 [==============================] - 212s - loss: 0.1749 - acc: 0.9342 - val_loss: 0.1408 - val_acc: 0.9422\n",
      "Epoch 4/50\n",
      "229/229 [==============================] - 212s - loss: 0.1615 - acc: 0.9334 - val_loss: 0.1658 - val_acc: 0.9322\n",
      "Epoch 5/50\n",
      "229/229 [==============================] - 212s - loss: 0.1500 - acc: 0.9430 - val_loss: 0.1400 - val_acc: 0.9522\n",
      "Epoch 6/50\n",
      "229/229 [==============================] - 212s - loss: 0.1674 - acc: 0.9380 - val_loss: 0.1342 - val_acc: 0.9600\n",
      "Epoch 7/50\n",
      "229/229 [==============================] - 212s - loss: 0.1690 - acc: 0.9299 - val_loss: 0.1469 - val_acc: 0.9489\n",
      "Epoch 8/50\n",
      "229/229 [==============================] - 211s - loss: 0.1657 - acc: 0.9383 - val_loss: 0.1480 - val_acc: 0.9522\n",
      "Epoch 9/50\n",
      "229/229 [==============================] - 211s - loss: 0.1573 - acc: 0.9437 - val_loss: 0.1475 - val_acc: 0.9489\n",
      "Epoch 10/50\n",
      "229/229 [==============================] - 212s - loss: 0.1507 - acc: 0.9388 - val_loss: 0.1631 - val_acc: 0.9433\n",
      "Epoch 11/50\n",
      "229/229 [==============================] - 212s - loss: 0.1615 - acc: 0.9388 - val_loss: 0.1812 - val_acc: 0.9267\n",
      "Epoch 12/50\n",
      "229/229 [==============================] - 212s - loss: 0.1548 - acc: 0.9375 - val_loss: 0.1344 - val_acc: 0.9567\n",
      "Epoch 13/50\n",
      "229/229 [==============================] - 212s - loss: 0.1610 - acc: 0.9424 - val_loss: 0.1584 - val_acc: 0.9400\n",
      "Epoch 14/50\n",
      "229/229 [==============================] - 212s - loss: 0.1514 - acc: 0.9473 - val_loss: 0.1450 - val_acc: 0.9533\n",
      "Epoch 15/50\n",
      "229/229 [==============================] - 212s - loss: 0.1518 - acc: 0.9479 - val_loss: 0.1337 - val_acc: 0.9544\n",
      "Epoch 16/50\n",
      "229/229 [==============================] - 212s - loss: 0.1513 - acc: 0.9388 - val_loss: 0.1789 - val_acc: 0.9311\n",
      "Epoch 17/50\n",
      "229/229 [==============================] - 212s - loss: 0.1551 - acc: 0.9386 - val_loss: 0.1398 - val_acc: 0.9500\n",
      "Epoch 18/50\n",
      "229/229 [==============================] - 212s - loss: 0.1580 - acc: 0.9457 - val_loss: 0.1481 - val_acc: 0.9400\n",
      "Epoch 19/50\n",
      "229/229 [==============================] - 212s - loss: 0.1666 - acc: 0.9383 - val_loss: 0.1294 - val_acc: 0.9611\n",
      "Epoch 20/50\n",
      "229/229 [==============================] - 212s - loss: 0.1489 - acc: 0.9446 - val_loss: 0.1513 - val_acc: 0.9500\n",
      "Epoch 21/50\n",
      "229/229 [==============================] - 213s - loss: 0.1385 - acc: 0.9528 - val_loss: 0.1481 - val_acc: 0.9550\n",
      "Epoch 22/50\n",
      "229/229 [==============================] - 212s - loss: 0.1553 - acc: 0.9398 - val_loss: 0.1594 - val_acc: 0.9411\n",
      "Epoch 23/50\n",
      "229/229 [==============================] - 212s - loss: 0.1408 - acc: 0.9490 - val_loss: 0.1425 - val_acc: 0.9567\n",
      "Epoch 24/50\n",
      "229/229 [==============================] - 212s - loss: 0.1336 - acc: 0.9484 - val_loss: 0.1324 - val_acc: 0.9556\n",
      "Epoch 25/50\n",
      "229/229 [==============================] - 212s - loss: 0.1519 - acc: 0.9407 - val_loss: 0.1411 - val_acc: 0.9522\n",
      "Epoch 26/50\n",
      "229/229 [==============================] - 212s - loss: 0.1424 - acc: 0.9410 - val_loss: 0.1844 - val_acc: 0.9356\n",
      "Epoch 27/50\n",
      "229/229 [==============================] - 212s - loss: 0.1361 - acc: 0.9509 - val_loss: 0.1534 - val_acc: 0.9444\n",
      "Epoch 28/50\n",
      "229/229 [==============================] - 212s - loss: 0.1400 - acc: 0.9478 - val_loss: 0.1229 - val_acc: 0.9589\n",
      "Epoch 29/50\n",
      "229/229 [==============================] - 212s - loss: 0.1442 - acc: 0.9470 - val_loss: 0.1383 - val_acc: 0.9622\n",
      "Epoch 30/50\n",
      "229/229 [==============================] - 212s - loss: 0.1327 - acc: 0.9514 - val_loss: 0.1435 - val_acc: 0.9556\n",
      "Epoch 31/50\n",
      "229/229 [==============================] - 212s - loss: 0.1424 - acc: 0.9487 - val_loss: 0.1434 - val_acc: 0.9522\n",
      "Epoch 32/50\n",
      "229/229 [==============================] - 212s - loss: 0.1411 - acc: 0.9468 - val_loss: 0.1224 - val_acc: 0.9533\n",
      "Epoch 33/50\n",
      "229/229 [==============================] - 212s - loss: 0.1356 - acc: 0.9509 - val_loss: 0.1243 - val_acc: 0.9600\n",
      "Epoch 34/50\n",
      "229/229 [==============================] - 212s - loss: 0.1289 - acc: 0.9552 - val_loss: 0.1408 - val_acc: 0.9556\n",
      "Epoch 35/50\n",
      "229/229 [==============================] - 212s - loss: 0.1361 - acc: 0.9495 - val_loss: 0.1316 - val_acc: 0.9500\n",
      "Epoch 36/50\n",
      "229/229 [==============================] - 212s - loss: 0.1294 - acc: 0.9511 - val_loss: 0.1186 - val_acc: 0.9656\n",
      "Epoch 37/50\n",
      "229/229 [==============================] - 212s - loss: 0.1375 - acc: 0.9484 - val_loss: 0.1336 - val_acc: 0.9500\n",
      "Epoch 38/50\n",
      "229/229 [==============================] - 212s - loss: 0.1321 - acc: 0.9501 - val_loss: 0.1552 - val_acc: 0.9500\n",
      "Epoch 39/50\n",
      "229/229 [==============================] - 212s - loss: 0.1259 - acc: 0.9541 - val_loss: 0.1577 - val_acc: 0.9533\n",
      "Epoch 40/50\n",
      "229/229 [==============================] - 212s - loss: 0.1361 - acc: 0.9520 - val_loss: 0.1914 - val_acc: 0.9233\n",
      "Epoch 41/50\n",
      "229/229 [==============================] - 212s - loss: 0.1381 - acc: 0.9435 - val_loss: 0.1464 - val_acc: 0.9511\n",
      "Epoch 42/50\n",
      "229/229 [==============================] - 212s - loss: 0.1298 - acc: 0.9517 - val_loss: 0.1591 - val_acc: 0.9522\n",
      "Epoch 43/50\n",
      "229/229 [==============================] - 212s - loss: 0.1277 - acc: 0.9541 - val_loss: 0.0897 - val_acc: 0.9756\n",
      "Epoch 44/50\n",
      "229/229 [==============================] - 212s - loss: 0.1390 - acc: 0.9497 - val_loss: 0.1268 - val_acc: 0.9589\n",
      "Epoch 45/50\n",
      "229/229 [==============================] - 212s - loss: 0.1220 - acc: 0.9533 - val_loss: 0.1564 - val_acc: 0.9611\n",
      "Epoch 46/50\n",
      "229/229 [==============================] - 212s - loss: 0.1383 - acc: 0.9457 - val_loss: 0.1406 - val_acc: 0.9567\n",
      "Epoch 47/50\n",
      "229/229 [==============================] - 212s - loss: 0.1445 - acc: 0.9460 - val_loss: 0.1361 - val_acc: 0.9578\n",
      "Epoch 48/50\n",
      "229/229 [==============================] - 212s - loss: 0.1292 - acc: 0.9552 - val_loss: 0.1252 - val_acc: 0.9556\n",
      "Epoch 49/50\n",
      "229/229 [==============================] - 212s - loss: 0.1325 - acc: 0.9539 - val_loss: 0.1236 - val_acc: 0.9678\n",
      "Epoch 50/50\n",
      "229/229 [==============================] - 212s - loss: 0.1344 - acc: 0.9509 - val_loss: 0.1712 - val_acc: 0.9289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f837711e2e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_training_samples = train_generator.n\n",
    "num_validation_samples = validation_generator.n\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_training_samples//batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('invasive_species.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_folder,\n",
    "    batch_size=batch_size,\n",
    "    target_size = (IMG_WIDTH, IMG_HEIGHT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = test_generator.n\n",
    "test_predictions = model.predict_generator(test_generator, num_test_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.22737179e-10,   1.00000000e+00],\n",
       "       [  4.58515040e-12,   1.00000000e+00],\n",
       "       [  9.63363469e-01,   2.90614516e-02],\n",
       "       [  7.25922585e-01,   3.29287767e-01],\n",
       "       [  4.03726155e-08,   9.99999881e-01],\n",
       "       [  9.11682665e-01,   8.85884538e-02],\n",
       "       [  9.59909618e-01,   4.19592559e-02],\n",
       "       [  8.00499667e-09,   1.00000000e+00],\n",
       "       [  8.28474045e-01,   1.89637035e-01],\n",
       "       [  7.22374737e-01,   2.96274900e-01],\n",
       "       [  1.65485492e-08,   1.00000000e+00],\n",
       "       [  1.21329986e-05,   9.99985218e-01],\n",
       "       [  2.11506276e-07,   9.99999762e-01],\n",
       "       [  9.08112696e-10,   1.00000000e+00],\n",
       "       [  8.71309042e-01,   1.15887389e-01],\n",
       "       [  9.79272425e-01,   2.07115673e-02],\n",
       "       [  8.60504091e-01,   1.34673640e-01],\n",
       "       [  4.83975671e-02,   9.48808670e-01],\n",
       "       [  7.50365257e-01,   2.33482733e-01],\n",
       "       [  1.61438706e-07,   9.99999881e-01]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "invasive = test_predictions[:,1]\n",
    "names = np.arange(1, len(invasive)+1, dtype=np.int32)\n",
    "submission_array = np.stack((names, invasive), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('submission.npy', submission_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
