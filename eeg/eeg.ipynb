{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import data_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_utils\n",
    "\n",
    "\n",
    "submission_data_path = os.path.join('data', 'test')\n",
    "train_data_path = os.path.join('data', 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data_from_csv():\n",
    "    train_files = data_utils.get_train_files(train_data_path)\n",
    "\n",
    "    train_data_as_array, train_data_as_list = data_utils.get_raw_train_data(train_files)\n",
    "    \n",
    "    return train_data_as_array, train_data_as_list\n",
    "\n",
    "train_data_as_array, train_data_as_list = load_train_data_from_csv()\n",
    "data_utils.pickle_obj(train_data_as_list, 'train_data_as_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_labels_from_csv():\n",
    "    label_files = data_utils.get_label_files(train_data_path)\n",
    "    train_labels = [data_utils.load_labels(f) for f in label_files]\n",
    "    return train_labels\n",
    "\n",
    "train_labels = load_train_labels_from_csv()\n",
    "data_utils.pickle_obj(train_labels, 'train_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(train_data_as_array)\n",
    "data_utils.pickle_obj(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_data(scaler, train_data, train_labels, sequence_size):    \n",
    "    num_train_inputs_total = 0\n",
    "    num_cols = train_data[0].shape[1]\n",
    "    num_outputs = train_labels[0].shape[1]\n",
    "    for td in train_data:\n",
    "        num_rows = td.shape[0]    \n",
    "        end_idx = num_rows - (num_rows%sequence_size)\n",
    "        num_train_inputs_total += end_idx//sequence_size\n",
    "\n",
    "\n",
    "    train_data_inputs = np.empty((num_train_inputs_total, sequence_size, num_cols))\n",
    "    train_label_inputs = np.empty((num_train_inputs_total, num_outputs))\n",
    "    start_idx = 0\n",
    "    for (td, labels) in zip(train_data, train_labels):\n",
    "        num_rows = td.shape[0]    \n",
    "        end_idx = num_rows - (num_rows%sequence_size)\n",
    "        num_train_inputs = end_idx//sequence_size\n",
    "\n",
    "        train_data_range = range(start_idx, start_idx + num_train_inputs)\n",
    "        td = scaler.transform(td)\n",
    "        train_data_inputs[train_data_range] = \\\n",
    "                np.array([td[i:i+sequence_size] for i in range(0, end_idx, sequence_size)])\n",
    "        train_label_inputs[train_data_range] = np.array(labels[:num_train_inputs])\n",
    "\n",
    "        start_idx += num_train_inputs    \n",
    "    return train_data_inputs, train_label_inputs\n",
    "\n",
    "def load_training_data(sequence_size):\n",
    "    train_data = data_utils.unpickle_obj('train_data_as_list.pkl')\n",
    "    train_labels = data_utils.unpickle_obj('train_labels.pkl')\n",
    "    scaler = data_utils.unpickle_obj('scaler.pkl')\n",
    "    X,Y = format_data(scaler, train_data, train_labels, sequence_size)\n",
    "    return X,Y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_data(train_data, train_labels, split_fraction=0.1):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=split_fraction, random_state=42)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "train_data, train_labels = load_training_data(sequence_size=100)\n",
    "X_train, X_test, Y_train, Y_test = split_train_data(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "# def build_rnn_model(layers):\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     model.add(LSTM(\n",
    "#     input_dim=layers[0],\n",
    "#     output_dim=layers[1],\n",
    "#     return_sequences=True))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(LSTM(\n",
    "#         layers[2],\n",
    "#         return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(Dense(\n",
    "#         output_dim=layers[3]))\n",
    "#     model.add(Activation(\"linear\"))\n",
    "#     model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "\n",
    "#     return model\n",
    "\n",
    "def build_rnn_model(layers):\n",
    "    model = Sequential()  \n",
    "    model.add(LSTM(layers[0], layers[1], return_sequences=False))  \n",
    "    model.add(Dense(layers[1], layers[2]))  \n",
    "    model.add(Activation(\"linear\"))  \n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`LSTM` can accept only 1 positional arguments ('units',), but you passed the following positional arguments: [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-fbf23d2ec1ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodeltmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# modeltmp.add( )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shaurya/anaconda3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m                                     \u001b[1;34m', but you passed the following '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                                     \u001b[1;34m'positional arguments: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                                     str(list(args[1:])))\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue_conversions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: `LSTM` can accept only 1 positional arguments ('units',), but you passed the following positional arguments: [2, 3]"
     ]
    }
   ],
   "source": [
    "modeltmp = Sequential()\n",
    "xx = LSTM(2, 3, return_sequences=False)\n",
    "\n",
    "\n",
    "# modeltmp.add( )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
