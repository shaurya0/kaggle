{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shaur\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = r'data/train/train.csv'\n",
    "test_path = r'data/test'\n",
    "test_files = glob(path.join(test_path, '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numpy_files(train_csv_file, output_folder):\n",
    "    if path.exists(path.join(output_folder, 'train_acoustic_data.npy')):\n",
    "        print('Numpy array exists, skipping')\n",
    "        return\n",
    "    \n",
    "    train_df_chunked = pd.read_csv(train_csv_file, chunksize=10000000)\n",
    "    acoustic_data_filepath = path.join(output_folder, 'train_acoustic_data')\n",
    "    \n",
    "    ttf_filepath = path.join(output_folder, 'train_time_to_failure')\n",
    "    acoustic_data = list()\n",
    "    time_to_failure = list()\n",
    "\n",
    "    for chunk in train_df_chunked:\n",
    "        a = chunk['acoustic_data'].values\n",
    "        t = chunk['time_to_failure'].values\n",
    "        acoustic_data.append(a.astype(np.int16))\n",
    "        time_to_failure.append(t.astype(np.float32))\n",
    "    \n",
    "    acoustic_data = np.concatenate(acoustic_data)\n",
    "    time_to_failure = np.concatenate(time_to_failure)\n",
    "    np.save(acoustic_data_filepath, acoustic_data)\n",
    "    np.save(ttf_filepath, time_to_failure)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array exists, skipping\n"
     ]
    }
   ],
   "source": [
    "create_numpy_files(train_csv_file=train_file, output_folder='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strided_app(a, L, S):\n",
    "    nrows = ((a.shape[0]-L)//S)+1\n",
    "    \n",
    "    n = a.strides[0]    \n",
    "    if len(a.shape) > 1:\n",
    "        ncols = a.shape[1]        \n",
    "        strides = (S*n, n, a.strides[1])\n",
    "    else:\n",
    "        ncols = 1\n",
    "        strides = (S*n,n)\n",
    "    shape = (nrows,L, ncols)\n",
    "    \n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=(S*n,n, a.strides[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsequences(x, window_size, step=1):\n",
    "    # x : (batch_size, seq_len, features)\n",
    "    # Split a batch of sequence data to generate all the subsequences\n",
    "    # with a step size of 1 are returned.        \n",
    "    batch_size = x.shape[0]\n",
    "    seq_len = x.shape[1]\n",
    "    if len(x.shape) > 2:\n",
    "        num_features = x.shape[2]\n",
    "    else:\n",
    "        num_features = 1\n",
    "        \n",
    "    \n",
    "    assert(window_size <= seq_len)\n",
    "    num_steps = (seq_len - window_size + 1)//step\n",
    "    nrows = ((seq_len - window_size)//step) + 1\n",
    "    \n",
    "    batched_subsequences = np.empty((batch_size, nrows, window_size, num_features))\n",
    "    for i in range(batch_size):\n",
    "        batched_subsequences[i,:,:] = strided_app(x[i], window_size, step)\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        yield batched_subsequences[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data_from_numpy_files(folder):\n",
    "    acoustic_data = np.load(path.join(folder, 'train_acoustic_data.npy'))\n",
    "    time_to_failure = np.load(path.join(folder, 'train_time_to_failure.npy'))\n",
    "    return acoustic_data, time_to_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_data, time_to_failure = load_train_data_from_numpy_files('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_data = acoustic_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_data = np.expand_dims(acoustic_data, axis=1)\n",
    "scaler = preprocessing.StandardScaler(copy=False)\n",
    "acoustic_data = scaler.fit_transform(acoustic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629145480, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acoustic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_SIZE = 165000\n",
    "remainder = time_to_failure.shape[0] % 165000\n",
    "X = acoustic_data[:-remainder]\n",
    "y = time_to_failure[:-remainder]\n",
    "X_segments = np.reshape(X, (-1, SEGMENT_SIZE, 1))\n",
    "y_segments = np.reshape(y, (-1, SEGMENT_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(X_segments.shape[0]*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_segments[:split_idx]\n",
    "y_train = y_segments[:split_idx]\n",
    "X_test = X_segments[split_idx:]\n",
    "y_test = y_segments[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
